# The GoodLaw Project :balance_scale:

## :book: Overview

The GoodLaw Project is an open-source repository offering a set of benchmarking prompts for evaluating the output quality of Large Legal Language Models (LLLMs) in various legal contexts. Moderated by TrueLaw, this initiative serves as a straightforward tool for those interested in assessing LLLMs.

## :question: Why GoodLaw?

As machine learning technologies find their way into the legal domain, there's a growing need for simple yet effective ways to evaluate these technologies. The GoodLaw Project aims to fill this need by providing a benchmark of prompts that can be used to assess the quality of LLLM outputs.

## :star: Features

- **Benchmarking Prompts**: A curated set of prompts for assessing LLLMs in different legal contexts.
- **Open-Source**: The repository is open for community contributions.

## :bar_chart: Quantitative Evaluation

For those interested in a more quantitative evaluation, we recommend using the [ARC Framework](https://github.com/Your_Link_To_ARC_Framework), which focuses on Accuracy, Relevance, and Completeness.

## :handshake: How to Contribute

- Add new prompts under the `Benchmarking_Prompts` folder.
- Improve or add to the usage guidelines in the `Docs` folder.

For detailed guidelines, please read [`CONTRIBUTING.md`](Contributing/CONTRIBUTING.md).

## :page_with_curl: License

This project is licensed under the MIT License - see the [`LICENSE.md`](LICENSE.md) file for details.
